<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta property="og:type" content="website">
<meta property="og:title" content="Learn Machine Learning">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Learn Machine Learning">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Learn Machine Learning">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>Learn Machine Learning</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Learn Machine Learning</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">AI民间玩家</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/02/12/HMM推导及实现/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Spencer">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/head.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Learn Machine Learning">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/02/12/HMM推导及实现/" itemprop="url">HMM推导及实现(一)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-02-12T17:52:18+08:00">
                2018-02-12
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>隐马尔可夫模型（Hidden Markov Model，HMM）是马尔可夫过程的一个扩展，而马尔可夫过程是指满足马尔可夫假设的随机过程。马尔可夫假设是指一个随机变量的当前状态只依赖于前一个随机变量的状态，和其他的因素都无关。如下图所示：<img src="../../public/images/马尔科夫链.png" alt="马尔科夫链"></p>
<p>其中 <span class="math inline">\(z_n\)</span> 的值只受 <span class="math inline">\(z_{n-1}\)</span> 的值影响。</p>
<p>然后隐马尔可夫模型再此基础上引入了这些状态的输出，也就是描述了由一个隐藏的马尔可夫链生成不可观测的状态随机序列，再由各个状态生成观测随机序列的过程。如下图所示：<img src="../../public/images/隐马尔可夫模型.png" alt="隐马尔可夫模型"></p>
<p>其中，<span class="math inline">\(z_1,z_2,\dots,z_{n-1},z_{n},z_{n+1}\)</span> 即不可观测的状态随机序列，它们是一个马尔可夫链，并且每个状态又生成了可观测的状态序列 <span class="math inline">\(x_1,x_2,\dots,x_{n-1},x_n,x_{n+1}\)</span>。而在现实数据中，存在很多这样的问题，比如大家都知道的中文分词问题，每个字都是一个可观测的值，它们组成了一个可观测序列，但是每个字是如何组成一个词的这个状态我们是无法直接观测到的，所以被称为隐变量，例如可以假设这里的隐变量有以下的状态序列空间 <span class="math inline">\(\{B,M,S,E\}\)</span>,其中<span class="math inline">\(B\)</span>表示这个字是一个词的开头组成，<span class="math inline">\(M\)</span>表示这个字是一个词的中间部分，<span class="math inline">\(S\)</span> 表示这个字是单独成词，而<span class="math inline">\(E\)</span>表示这个字在这个词的结束。如果是这样我们就能知道这个词是由哪些字组成的，比如“为人民服务”这个字序列对应的隐状态标记序列为“<span class="math inline">\(SBEBE\)</span>”，这样我们就能够达到中文分词的目的了。所以，当我们输入观测序列给HMM，它就能够给我们这个观测序列的标记序列，这个问题被称为HMM的预测问题，这里先不展开，后面再详细说。 &lt; !–more–&gt; 接下来，我们深入研究一下HMM的一些问题。通过上面的讲解，已经知道了隐变量有一个可能的状态序列，将其定义为 <span class="math inline">\(I=\{i_1,i_2,\dots,i_{T-1},i_{T} \}\)</span> （可以认为是HMM的Input，以后我们就把它叫做状态序列，<span class="math inline">\(T\)</span> 表示此时这个HMM的状态序列的长度），观测变量也有一个可能的取值，它们对应为状态序列 <span class="math inline">\(I\)</span>的输出，定义为 <span class="math inline">\(O=\{o_1,o_2,\dots,o_T \}\)</span>（可以认为是HMM的Output，称为观测序列）。需要注意的是，这里的 <span class="math inline">\(i_{index} 以及 o_{index}\)</span> 表示的是所有状态和观测集合的位置。我们还需要定义一个所有状态（隐变量）的集合为 <span class="math inline">\(Q=\{q_1,q_2,\dots,q_N\}\)</span> ，<span class="math inline">\(N\)</span> 表示所有状态的可能个数，所有可观测状态的集合为 <span class="math inline">\(V=\{v_1,v_2,\dots,v_M\}，M为所有可能的观测状态\)</span>。那么<span class="math inline">\(I\)</span>就是从状态集合<span class="math inline">\(Q\)</span>中抽取出来的序列，<span class="math inline">\(O\)</span>就是从观测集合<span class="math inline">\(V\)</span>中抽取出来的序列。</p>
<p>在这个HMM的图中，每一个状态都有一个初始概率，定义为一个向量 <span class="math inline">\(\pi = (\pi_i),\pi_i=P(i_1=q_i)\)</span>，表示时刻 <span class="math inline">\(t=1\)</span> 的状态为 <span class="math inline">\(q_i\)</span> 的概率。状态和状态之间都有一个依据时间的转移概率，比如状态 <span class="math inline">\(i_1\)</span>从时间 <span class="math inline">\(t\)</span>在下一个时间 <span class="math inline">\(t+1\)</span>变成状态 <span class="math inline">\(i_2\)</span> 会有一个概率，为了方便，我们记时刻<span class="math inline">\(t\)</span>时的状态为 <span class="math inline">\(q_t\)</span>，那么把这个转移概率表示成 <span class="math inline">\(a_{ij}=p(q_{t+1} = j | q_t = i)\)</span>，因为是转移，后一个状态依赖于前一个状态，所以这里是条件概率。然而，每一个状态从时刻 <span class="math inline">\(t\)</span> 可能会在下一个时刻 <span class="math inline">\(t+1\)</span> 转移到状态集合中的任何一个状态，状态一共有 <span class="math inline">\(N\)</span> 个，所以概率有 <span class="math inline">\(N \times N\)</span> 个，于是把所有的概率表示为一个概率矩阵 <span class="math inline">\(A = [a_{ij}]_{N \times N}\)</span>，这个矩阵被称为状态概率矩阵。同样地，我们的状态会在 <span class="math inline">\(t\)</span> 时刻生成一个观测，状态有 <span class="math inline">\(N\)</span> 个，观测有 <span class="math inline">\(M\)</span> 个，会得到一个 <span class="math inline">\(N \times M\)</span> 的观测概率矩阵 <span class="math inline">\(B=[b_{j}(k)]_{N \times M}\)</span>，其中 <span class="math inline">\(b_j(k) = P(o_t=v_k |i_t = q_j),k=1,2,\dots,M;j=1,2,\dots,N\)</span>，表示，在时刻 <span class="math inline">\(t\)</span>处于状态<span class="math inline">\(q_j\)</span>的条件下生成观测 <span class="math inline">\(v_k\)</span> 的概率。</p>
<p>我们把上面定义的三个参数 <span class="math inline">\(\lambda = (\pi,A,B)\)</span> 称为HMM的三要素，它们也是模型的参数，也就是说有了这个 <span class="math inline">\(\lambda\)</span>，我们就能够得到一个HMM了。由此，我们引出了HMM的三个问题： - 概率计算问题： 指在 <span class="math inline">\(\lambda\)</span> 和观测序列 <span class="math inline">\(O\)</span> 都已知的情况下，计算输出观测序列的概率，即求 <span class="math inline">\(P(O|\lambda)\)</span> - 学习问题： 指在观测序列 <span class="math inline">\(O\)</span> 已知的情况下，求得使得出现该观测序列概率最大的参数 <span class="math inline">\(\lambda\)</span>，即求 <span class="math inline">\(\lambda^* =\underset{\lambda}{\arg\max} P(O|\lambda)\)</span> - 预测问题： 指在 <span class="math inline">\(\lambda\)</span> 和观测序列 <span class="math inline">\(O\)</span> 都已知的情况下，计算最优可能的状态序列 <span class="math inline">\(I\)</span>,即求 <span class="math inline">\(I^*=\underset{I}{\arg\max }P(I|O;\lambda)\)</span></p>
<p>再进入这三个问题之前，先说说HMM是如何生成序列的，并且举一个HMM的例子，以熟悉上面定义的一些概念。关于生成序列，HMM是这样做的： - (1)使用初始概率向量 <span class="math inline">\(\pi\)</span> 产生状态 <span class="math inline">\(i_1\)</span>； - (2)令 <span class="math inline">\(t=1\)</span> - (3)按照状态 <span class="math inline">\(i_t\)</span> 的观测概率分布 <span class="math inline">\(b_{i_t}(k)\)</span> 生成 <span class="math inline">\(o_t\)</span> - (4)按照状态 <span class="math inline">\(i_t\)</span> 的状态转移概率分布 <span class="math inline">\(\{a_{i_ti_{t+1}}\}\)</span> 产生状态 <span class="math inline">\(i_{t+1}\)</span>,<span class="math inline">\(i_{t+1}=1,2,\dots,N\)</span> - (5) 令 <span class="math inline">\(t=t+1\)</span>；如果 <span class="math inline">\(t&lt;T\)</span>，转步(3)；否则，终止</p>
<p>下面举一个例子，假设有4个盒子，每个盒子里都装有红白两种颜色的球，盒子里的红白球数由下表给出。 盒子|1| 2| 3| 4 —–|—-|—-|—-|—- 红球数| 5| 3| 6|8 白球数|5|7|4|2 现在按照下面的方法抽球，产生一个球的颜色的观测序列：开始，从4个盒子里以等概率随机选取1个盒子，从这个盒子里随机抽出1个球，记录其颜色后，放回；然后，从当前盒子随机转移到下一个盒子，规则是：如果当前盒子是盒子1，那么下一盒子一定是盒子2，如果当前是盒子2或3，那么分别以概率0.4和0.6转移到左边或右边的盒子，如果当前是盒子4，那么各以0.5的概率停留在盒子4或转移到盒子3；确定转移的盒子后，再从这个盒子里随机抽出1个球，记录其颜色，放回；如此下去，重复进行5次，得到一个球的颜色的观测序列：<span class="math display">\[O=\{红，红，白，白，红\}\]</span>，在这个过程中，观察者只能观测到球的颜色的序列，观测不到球是从哪个盒子取出的，即观测不到盒子的序列。</p>
<p>在这个例子中有两个随机序列，一个是盒子的序列（状态序列），一个是球的颜色的观测序列（观测序列）。前者是隐藏的，只有后者是可观测的。这是一个隐马尔可夫模型的例子，根据所给条件，可以明确状态集合、观测集合、序列长度以及模型的三要素。</p>
<p>状态集合Q={盒子1，盒子2，盒子3，盒子4},N=4 观测集合V={红球，白球},M=2 由于是从4个盒子等概率随机选取1个盒子，所以初始概率向量为： <span class="math inline">\(\pi=[0.25,0.25,0.25,0.25]\)</span></p>
状态概率矩阵为： [ A =
<span class="math display">\[\begin{pmatrix}
    0 &amp; 1 &amp; 0 &amp; 0 \\
    0.4 &amp; 0 &amp; 0.6 &amp; 0 \\
    0 &amp; 0.4 &amp; 0 &amp; 0.6 \\
    0 &amp; 0 &amp; 0.5 &amp; 0.5 \\
    \end{pmatrix}
\]\]</span>
观测概率矩阵为： [ B =
<span class="math display">\[\begin{pmatrix}
    0.5 &amp; 0.5 \\
    0.3 &amp; 0.7 \\
    0.6 &amp; 0.4 \\
    0.8 &amp; 0.2 \\
    \end{pmatrix}
\]\]</span>
<h2 id="hmm的概率计算问题">HMM的概率计算问题</h2>
<p>下面就开始解决HMM最重要的三个问题了，首先是概率计算问题。有3种方法来计算这个问题： - 暴力计算 - 前向算法 - 后向算法</p>
<h3 id="暴力计算">暴力计算</h3>
<p>我们的问题是计算 <span class="math inline">\(P(O|\lambda)\)</span>。直接的思考方式是，先看看我们能计算出哪些概率，状态序列 <span class="math inline">\(I=(i_1,i_2,\dots,i_T)\)</span> 的概率是 <span class="math display">\[
P(I|\lambda)=\pi_{i_1}a_{i_1i_2}a_{i_2i_3} \dots a_{i_{T-1}i_{T}}
\]</span> 这个比较容易理解，首先产生 <span class="math inline">\(i_1\)</span> 状态，然后在 <span class="math inline">\(i_1\)</span>状态的条件下产生 <span class="math inline">\(i_2\)</span> 状态，通过转移概率不断向前推进。 再来看下 <span class="math inline">\(P(O|I,\lambda)\)</span>，它表示已知状态序列 <span class="math inline">\(I=(i_1,i_2,\dots,i_T)\)</span>，观测序列 <span class="math inline">\(O=(o_1,o_2,\dots,o_T)\)</span> 的概率。这个也可以直接算： <span class="math display">\[
P(O|I,\lambda)=b_{i_1}(o_1)b_{i_2}(o_2)\dots b_{i_{T}}(o_T)
\]</span> 这个也很直观，通过观测概率矩阵产生观测 <span class="math inline">\(o_1\)</span>，以此类推，直到产生所有的观测序列 <span class="math inline">\(O\)</span>。 然后，再让 <span class="math inline">\(P(O|\lambda)\)</span>和上面两个直观的结果看看能不能产生关系。我们发现： <span class="math display">\[
P(O|\lambda)=\sum_{I}P(O,I|\lambda)(别说你这步也看不懂)=\sum_{I}P(O|I,\lambda)P(I|\lambda)=\sum_{I}\pi_{i_1}a_{i_1i_2}a_{i_2i_3} \dots \\ a_{i_{T-1}i_{T}}b_{i_1}(o_1)b_{i_2}(o_2)\dots b_{i_{T}}(o_T)=\sum_{I}\pi_{i_1}b_{i_1}(o_1)a_{i_1i_2}b_{i_2}(o_2)\dots a_{i_{T-1}i_{T}}b_{i_{T}}(o_T)
\]</span> 上面这个就是最终的观测序列的概率。这个式子通过一个所有状态序列 <span class="math inline">\(I\)</span> 的加和，内部是一个乘积的形式，一共有 <span class="math inline">\(2T\)</span> 个因子相乘，而外面的加和因为 <span class="math inline">\(I\)</span>的状态序列是从所有 <span class="math inline">\(N\)</span> 个状态集合中选出来的，即每个状态有 <span class="math inline">\(N\)</span>种选择，一共有 <span class="math inline">\(T\)</span> 个序列，所以一共有 <span class="math inline">\(N^T\)</span>，根据乘法法则那么一共要计算 <span class="math inline">\(2TN^T\)</span> 次，时间复杂度也就是 <span class="math inline">\(O(TN^T)\)</span>，是指数级的。所以，我们需要找更快的算法。</p>
<h3 id="前向算法">前向算法</h3>
<p>前向算法的思想是动态规划，通过递推的方式求得最终答案。定义一个前向概率，如下图：</p>
<p><img src="../../public/images/前向-后向概率.png" alt="前向-后向概率"> 左半边虚线是前向概率的定义，右半边虚线是后向概率的定义。无论是前向概率还是后向概率，都是通过状态和观测来定义的，前向概率是指划定一个时间 <span class="math inline">\(t\)</span>，此时状态 <span class="math inline">\(q_t = i\)</span>，观测必须是 <span class="math inline">\(\{y_1,y_2,\dots,y_{t-1},y_{t}\}\)</span>，满足这两种情况的概率就是前向概率，用数学的方法说就是 <span class="math display">\[
\alpha_t(i)=P(y_1,y_2,\dots,y_t,q_t=i|\lambda)
\]</span> 后向概率和前向概率基本差不多，也是划到 <span class="math inline">\(q_t\)</span>，只不过是向后看，但是不包括观测 <span class="math inline">\(y_t\)</span>，而是从 <span class="math inline">\(y_{t+1}\)</span> 开始，即要求观测是 <span class="math inline">\(y_{t+1},y_{t+2},\dots,y_{T}\)</span>，状态是 <span class="math inline">\(q_t = i\)</span>，即后向概率为： <span class="math display">\[
\beta_t(i) = P(y_{t+1},y_{t+2},\dots,y_{T} |q_t=i,\lambda)
\]</span> 直观地理解就是一个从前往后看状态和观测，一个时从后往前看状态和观测。 而前向算法主要是依据前向概率的递推过程，根据上面的推导，我们知道: <span class="math inline">\(\alpha_t(i)=P(o_1,o_2,\dots,o_t,q_t=i|\lambda)\)</span>，利用递推的方式，我们需要找到 <span class="math inline">\(t-1\)</span> 时的前向概率和 <span class="math inline">\(t\)</span> 时的前向概率之间的关系， <span class="math inline">\(t-1\)</span> 时的前向概率中，状态为 <span class="math inline">\(q_{t-1}=i\)</span>，观测为 <span class="math inline">\(\{o_1,o_2,\dots,o_{t-1}\}\)</span>，那么怎样才能把这个变成 <span class="math inline">\(\alpha_t(i)\)</span> 呢？那么需要将 <span class="math inline">\(q_{t-1} = i\)</span> 变成 <span class="math inline">\(q_{t} = i\)</span>，当然观测也要变。其实并不难，为了更加直观，把 <span class="math inline">\(\alpha_t(i)\)</span> 和 <span class="math inline">\(\alpha_{t-1}(i)\)</span> 分别写成概率的形式： - <span class="math inline">\(\alpha_t(i)=P(o_1,o_2,\dots,o_t,q_t=i|\lambda)\)</span> - <span class="math inline">\(\alpha_{t-1}(i)=P(o_1,o_2,\dots,o_{t-1},q_{t-1}=i|\lambda)\)</span></p>
<p>我们发现，<span class="math inline">\(q_{t-1}=i\)</span>无论如何都无法通过状态转移概率矩阵直接跳到 <span class="math inline">\(q_{t}=i\)</span> 的，因为状态都是 <span class="math inline">\(i\)</span>，所以就想到再加一个跳板，状态 <span class="math inline">\(j\)</span>，也就是说如果我们知道了 <span class="math inline">\(P(o_1,o_2,\dots,o_{t-1},q_{t-1}=j,q_t=i|\lambda)\)</span>，就可以通过求和把状态 <span class="math inline">\(j\)</span> 给消掉： <span class="math display">\[
P(o_1,o_2,\dots,o_{t-1},q_t=i|\lambda)=
\sum_j P(o_1,o_2,\dots,o_{t-1},q_{t-1}=j,q_t=i|\lambda)
\]</span> 而求和符号中的式子可以通过下面的方法得到: <span class="math display">\[
P(o_1,o_2,\dots,o_{t-1},q_{t-1}=j,q_t=i|\lambda)=P(o_1,o_2,\dots,o_{t-1},q_{t-1}=j)a_{ji}=\alpha_j(t-1)a_{ji}
\]</span></p>
<p>而 <span class="math display">\[
P(o_1,o_2,\dots,o_{t},q_t=i|\lambda)=P(o_1,o_2,\dots,o_{t-1},q_t=i|\lambda)b_{i}(o_t)
\]</span> 最终得到： <span class="math display">\[
\alpha_t(i) = \sum_{j=1}^{N}\Big(\alpha_{t-1}(j)a_{ji}\Big)b_i(o_t)（注意区分 \alpha 和 a ）
\]</span></p>
<p>具体的递推过程为： - <span class="math inline">\(初值：\alpha_1(i)=\pi_{i}b_{i}(o_1)\)</span> - <span class="math inline">\(递推：对于t=1,2,\dots,T-1 \\ \alpha_{t+1}(i) = \sum_{j=1}^{N}\Big(\alpha_{t}(j)a_{ji}\Big)b_i(o_{t+1})\)</span> - <span class="math inline">\(最终：P(O|\lambda)=\sum_{i=1}^N\alpha_T(i)\)</span></p>
<h3 id="后向算法">后向算法</h3>
<p>后向算法的推导基本和前向算法一样，只是后向算法是从后向前算，初值为 <span class="math inline">\(\beta_T(i)=1\)</span>，因为后面没有了。 递推： <span class="math display">\[
对于t=T-1,T-2,\dots,1 \\
\beta_t(i) = \sum_{j=1}^N\Big(a_{ij}b_j(o_{t+1})\beta_{i+1}(j)\Big)
\]</span> 最终： <span class="math display">\[
P(O|\lambda)=\sum_{i=1}^N\pi_ib_i(o_1)\beta_1(i)
\]</span></p>
<h3 id="前后向概率的关系">前后向概率的关系</h3>
<p>由上得知前向概率为: <span class="math display">\[
\alpha_t(i)=P(o_1,o_2,\dots,o_t,q_t=i|\lambda)
\]</span></p>
<p>后向概率为： <span class="math display">\[
\beta_t(i)=P(o_{t+1},o_{t+2},\dots,o_T|q_t=i,\lambda)
\]</span></p>
<p>那么我们来算一下： <span class="math display">\[
P(q_t=i,O|\lambda)=P(O|q_t=i,\lambda)P(q_t=i|\lambda)\\=P(o_1,\dots,o_t|q_t=i,\lambda)P(q_t=i|\lambda)\\=P(o_1,\dots,o_t,o_{t+1},\dots o_T|q_t=i,\lambda)P(q_t=i|\lambda)\\
=P(o_1,\dots,o_t|q_t=i,\lambda)P(o_{t+1},\dots,o_T|q_t=i,\lambda)P(q_t=i|\lambda)\\=P(o_1,\dots,o_t,q_t=i|\lambda)P(o_{t+1},\dots,o_T|q_t=i,\lambda)\\=\alpha_t(i)\beta_t(i)
\]</span> 即 <span class="math display">\[
P(q_t=i,O|\lambda)=\alpha_t(i)\beta_t(i)
\]</span></p>
<p>求给定模型 <span class="math inline">\(\lambda\)</span>和观测 <span class="math inline">\(O\)</span>，在时刻<span class="math inline">\(t\)</span>处于状态 <span class="math inline">\(q_t=i\)</span>的概率： <span class="math display">\[
\gamma_t(i)=P(q_t=i|O,\lambda)
\]</span> 上面的式子被称为单个状态的概率。 根据前向后向概率的定义， <span class="math display">\[
P(q_t=i,O|\lambda)=\alpha_t(i)\beta_t(i) \\
\gamma_t(i)=P(q_t=i|O,\lambda)=\frac{P(q_t=i,O|\lambda)}{P(O|\lambda)}=\frac{\alpha_t(i)\beta_t(i)}{\sum_{i=1}^N\alpha_t(i)\beta_t(i)}
\]</span></p>
<p><span class="math inline">\(\gamma\)</span>的含义是指，在每个时刻<span class="math inline">\(t\)</span>选择在该时刻最有可能出现的状态<span class="math inline">\(i_t^*\)</span>，从而得到一个状态序列<span class="math inline">\(I^*=\{i_1^*,i_2^*,\dots,i_T^*\}\)</span>，将它作为预测的结果。</p>
<p>另外还有，两个状态的联合概率，即求给定模型 <span class="math inline">\(\lambda\)</span>和观测<span class="math inline">\(O\)</span>，在时刻<span class="math inline">\(t\)</span>处于状态<span class="math inline">\(q_t=i\)</span>并且时刻<span class="math inline">\(t+1\)</span>处于状态<span class="math inline">\(q_{t+1}=j\)</span>的概率。 <span class="math display">\[
\xi_t(i,j)=P(q_t=i,q_{t+1}=j|O,\lambda)=\frac{P(q_t=i,q_{t+1}=j,O|\lambda)}{P(O|\lambda)}\\=\frac{P(q_t=i,q_{t+1}=j,O|\lambda)}{\sum_{i=1}^{N}\sum_{j=1}^{N}P(q_t=i,q_{t+1}=j,O|\lambda)}\\P(q_t=i,q_{t+1}=j,O|\lambda)=\alpha_t(i)a_{ij}b_{j}(o_{t+1}\beta_{t+1}(j))
\]</span> 到达这里，没有什么问题吧？下面还有几个期望求一下： - 在观测<span class="math inline">\(o\)</span>下状态<span class="math inline">\(i\)</span>出现的期望(概率求和)： <span class="math display">\[
\sum_{t=1}^T\gamma_t(i)
\]</span> - 在观测<span class="math inline">\(O\)</span>下状态<span class="math inline">\(i\)</span>转移到状态<span class="math inline">\(j\)</span>的期望： <span class="math display">\[
\sum_{t=1}^{T-1}\xi_t(i,j)
\]</span> 这些公式后面会用到。至此，我们解决了HMM的概率计算问题。接下来时HMM的学习问题，即如何通过数据学得模型的参数 <span class="math inline">\(\lambda\)</span>。 ## HMM的学习问题 HMM的学习问题主要也有两个算法： - 有监督学习算法：数据包括观测序列和状态序列 - 鲍姆韦尔奇算法：数据只有观测序列 ### 有监督学习算法 估计参数最常用的是用极大似然估计，假设训练数据包含 <span class="math inline">\(S\)</span>个长度相同的观测序列和对应的状态序列 <span class="math inline">\(\{(O_1,I_1),(O_2,I_2),(O_3,I_3),\dots,(O_S,I_S)\}\)</span>。</p>
<ul>
<li><p>转移概率 <span class="math inline">\(a_{ij}\)</span> 的估计<br>
设样本中时刻 <span class="math inline">\(t\)</span> 处于状态 <span class="math inline">\(i\)</span> 时刻 <span class="math inline">\(t+1\)</span> 转移到状态 <span class="math inline">\(j\)</span>的频数为 <span class="math inline">\(A_{ij}\)</span>，那么状态转移概率 <span class="math inline">\(a_{ij}\)</span> 的估计是： <span class="math display">\[
\hat{a}_{ij}=\frac{A_{ij}}{\sum_{j=1}^NA_{ij}}
\]</span></p></li>
<li><p>观测概率 <span class="math inline">\(b_{i}(k)\)</span> 的估计<br>
设样本中状态为 <span class="math inline">\(j\)</span> 并且观测为 <span class="math inline">\(k\)</span> 的频数是 <span class="math inline">\(B_{jk}\)</span>，那么状态为 <span class="math inline">\(j\)</span> 观测为 <span class="math inline">\(k\)</span> 的概率 <span class="math inline">\(b_j(k)\)</span> 的估计是： <span class="math display">\[
\hat{b}_j(k)=\frac{B_{jk}}{\sum_{k=1}^{M}B_{jk}}
\]</span></p></li>
<li><p>初始状态概率 <span class="math inline">\(\pi_i\)</span> 的估计 <span class="math inline">\(\hat{\pi}_i\)</span>为 <span class="math inline">\(S\)</span> 个样本中初始状态为 <span class="math inline">\(q_i\)</span> 的频率。 ### 鲍姆韦尔奇（Baum-Welch）算法 假设给定训练数据只包含 <span class="math inline">\(S\)</span> 个长度为 <span class="math inline">\(T\)</span> 的观测序列 <span class="math inline">\(\{O_1,O_2,\dots,O_S\}\)</span> 而没有对应的状态序列，目标时学习隐马尔可夫模型 <span class="math inline">\(\lambda=(A,B,\pi)\)</span> 的参数。我们将观测序列数据看作观测数据 <span class="math inline">\(O\)</span>，状态序列数据看作不可观测的隐数据 <span class="math inline">\(I\)</span>，那么隐马尔科夫模型事实上是一个含有隐变量的概率模型 <span class="math display">\[
P(O|\lambda)=\sum_IP(O|I,\lambda)P(I|\lambda)
\]</span> 它的参数可以由EM算法实现。下面介绍一下EM算法的由来和推导。</p></li>
</ul>
<h4 id="em算法">EM算法</h4>
<p>一句话，EM算法是用来寻找含有隐变量的模型的参数的。假设有训练集 <span class="math inline">\(\{x^{(1)},x^{(2)},\dots,x^{(m)}\}\)</span>，包含 <span class="math inline">\(m\)</span> 个独立样本，希望从中找到该组数据的模型 <span class="math inline">\(p(x,z)\)</span> 的参数。思想也很简单，通过极大似然估计法，对观测到的数据<span class="math inline">\(x\)</span>取对数似然函数: <span class="math display">\[
l(\theta)=\sum_{i=1}^m\log p(x;\theta)=\sum_{i=1}^m\log\sum_zp(x,z;\theta)
\]</span> 而 <span class="math inline">\(z\)</span>时隐随机变量，不方便直接找到参数估计。于是前辈们想出了一个策略：计算 <span class="math inline">\(l(\theta)\)</span> 下界，求该下界的最大值；重复该过程，直到收敛到局部最大值。请看下面这张图：</p>
<p><img src="../../public/images/EM.png"></p>
<p>紫色的 <span class="math inline">\(l(\theta)\)</span> 函数，我们先找到一个函数 <span class="math inline">\(r(x|\theta)\)</span>去迭代逼近 <span class="math inline">\(p(x|\theta)\)</span>，先给定一个初值（绿色线），再求出这个 <span class="math inline">\(r(x|\theta)\)</span> 的最大值，并且保证 <span class="math inline">\(r(x|\theta)\)</span> 函数值比 <span class="math inline">\(p(x|\theta)\)</span> 函数值小，下一次就用红色的线代替原来的初值不断迭代，直到收敛到一个局部的最大值。接下来推导一下，推导过程中使用到了一个著名的不等式-Jensen不等式，简单来说，就是凸函数的割线在该函数的上方，并且可以扩展到概率期望上。这里暂时先不证明了，有机会再完善，只要记住：f是一个凸函数，<span class="math inline">\(X\)</span>随机变量，则： <span class="math display">\[
E[f(X)] &gt;=f(EX)
\]</span> 函数的期望大于等于期望的函数。</p>
<p><span class="math display">\[l(\theta)=\sum_{i=1}^m\log \sum_{z} p(x,z;\theta)=\sum_{i=1}^m \log \sum_{z^{(i)}}p(x^{(i)},z^{(i)};\theta)=\sum_{i=1}^m \log \sum_{z^{(i)}}Q_i(z^{(i)})\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}
\]</span> 上面我们假设了 <span class="math inline">\(Q_i\)</span> 是 <span class="math inline">\(z\)</span>的某一个分布，<span class="math inline">\(Q_i &gt;= 0\)</span>。在最后一个式子中，我们可以把 <span class="math inline">\(\log \sum_{z^{(i)}}Q_i(z^{(i)})\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}\)</span> 看成是一个对数函数，并且把 <span class="math inline">\(\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}\)</span>看成是一个随机变量 <span class="math inline">\(X\)</span>，那么这个求和就当于 <span class="math inline">\(X\)</span> 在分布 <span class="math inline">\(Q_i(z^{(i)})\)</span> 上的期望，也就是这里做了期望的函数操作，而对数是凹函数，那么根据上面的Jensen不等式有凹函数：期望的函数大于等于函数的期望。所以得到： <span class="math display">\[
l(\theta)=\sum_{i=1}^m\log \sum_{z} p(x,z;\theta)=\sum_{i=1}^m \log \sum_{z^{(i)}}p(x^{(i)},z^{(i)};\theta)=\sum_{i=1}^m \log \sum_{z^{(i)}}Q_i(z^{(i)})\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})} \\ \geq  \sum_{i=1}^m \sum_{z^{(i)}} Q_i(z^{(i)}) \log  \frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}
\]</span> 于是我们就找到了下界，那么这个等号什么时候成立呢？我们来看看对数函数的图像：</p>
<p><img src="../../public/images/log.png"> 一般来说函数的值都是大于割线的值，只有当两点 <span class="math inline">\(x_1=x_2\)</span>时，对数函数的值才等于割线的值。那么如果这个随机变量 <span class="math inline">\(X\)</span> 取一个定值 <span class="math inline">\(C\)</span>，就可以达到 <span class="math inline">\(x_1=x_2\)</span> 的目的。于是我们得到下面的式子： <span class="math display">\[
\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})} = C
\]</span></p>
<p>也就是说 <span class="math display">\[
Q_i(z^{(i)}) \propto p(x^{(i)},z^{(i)};\theta)
\]</span> <span class="math inline">\(Q_i(z^{(i)})\)</span> 是一个分布，加和应该为1，如果希望把正比符号变成等号，那么 <span class="math display">\[
Q_i(z^{(i)})=\frac{p(x^{(i)},z^{(i)};\theta)}{\sum_{z^{(i)}}p(x^{(i)},z^{(i)};\theta)}=\frac{p(x^{(i)},z^{(i)};\theta)}{p(x^{(i)};\theta)} = p(z^{(i)}|x^{(i)};\theta)
\]</span> 也就是说 <span class="math inline">\(Q_i(z^{(i)})\)</span> 取隐变量 <span class="math inline">\(z\)</span> 的条件概率时等号成立，这样可以得到一个紧确的解（时间关系，里面还有一些细节没有写出来，有机会再完善）。有了这个条件概率的式子，那么我们就能一开始给一个 <span class="math inline">\(\theta= \theta_1\)</span> 的初值，把这个条件概率算出来，算完之后把它带到对数似然函数中（此时的 <span class="math inline">\(\theta\)</span>）是未知的，然后求对数似然函数的极大值的那个 <span class="math inline">\(\theta = \theta^*\)</span>，算完之后，再用这个 <span class="math inline">\(\theta=\theta^*\)</span> 代入到 <span class="math inline">\(Q_i(z^{(i)})=p(z^{(i)}|x^{(i)};\theta)\)</span>，继续算 <span class="math inline">\(Q_i(z^{(i)})\)</span>，这样不断重复，直到 <span class="math inline">\(\theta\)</span> 收敛到一个稳定的值，就是我们要求的参数了。关于EM算法的收敛证明，暂时就不展开了。在进入鲍姆韦尔奇算法之前，再补充下EM算法相关东西，我们求到的条件概率分布 <span class="math inline">\(Q_i(z^{(i)})\)</span> 代入到极大化的那个式子实际上是求期望，求解的极大可以看成是对数似然函数关于这个 <span class="math inline">\(Q_i(z^{(i)})\)</span> 分布的期望，所以就有了江湖中传闻的 <span class="math inline">\(E\)</span> 步，有了这个就可以极大化了。我们可以把期望写成： <span class="math display">\[
Q(\theta,\theta^{(i)})=E_{z} = \sum_{z^{(i)}}p(z^{(i)}|x^{(i)},\theta^{(i)})\log p(x^{(i)},z^{(i)};\theta)
\]</span> 嗯，这样就完美了。其中，<span class="math inline">\(\theta^{(i)}\)</span> 是已知的，初值是随机给定的，<span class="math inline">\(\theta\)</span> 是我们每次迭代要求解的。极大化被称作M步。 有了EM算法，我们就能在鲍姆韦尔奇算法中求解HMM的参数了，前面已经说过，HMM参数的求解被认为是一个含隐变量的模型参数。 - 确定完全数据的对数似然函数<br>
所有观测数据写成 <span class="math inline">\(O=(o_1,o_2,\dots,o_T)\)</span> ，所有隐数据写成 <span class="math inline">\(I=(i_1,i_2,\dots,i_T)\)</span> ，完全数据是 <span class="math inline">\((O,I)=(o_1,o_2,\dots,o_T,i_1,i_2,\dots,i_T)\)</span> 。完全数据的对数似然函数是 <span class="math inline">\(\log P(O,I|\lambda)\)</span> 。 - E步<br>
求 <span class="math inline">\(Q\)</span> 函数 <span class="math inline">\(Q(\lambda,\overline{\lambda})\)</span>: <span class="math display">\[
Q(\lambda,\overline{\lambda})=\sum_{I}\log \Big(P(O,I|\lambda)\Big)P(I|O,\overline{\lambda})
\\=\sum_{I}\log \Big(P(O,I|\lambda)\Big)\frac{P(O,I|\overline{\lambda})}{P(O|\overline{\lambda})}\propto \sum_{I}\log \Big(P(O,I|\lambda)\Big)P(O,I|\overline{\lambda})\]</span> 其中，<span class="math inline">\(\overline{\lambda}\)</span> 是HMM当前估计值，<span class="math inline">\(\lambda\)</span> 是要极大化的HMM参数。 根据 <span class="math inline">\(P(O,I|\lambda)=P(O|I,\lambda)P(I|\lambda) =\pi_{i_1}b_{i_1}(o_1)a_{i_1,i_2}b_{i_2}(o_2)\dots a_{i_{T-1}i_T}b_{i_T}(o_T)\)</span></p>
<p>函数可写成三部分的加和： <span class="math display">\[
Q(\lambda,\overline{\lambda})=\sum_I\log P(O,I|\lambda)P(O,I|\overline{\lambda})=\sum_I\log \pi_{i_1}P(O,I|\overline{\lambda})\\+\sum_I\Big(\sum_{t=1}^{T-1}\log a_{i_ti_{t+1}}\Big)P(O,I|\overline{\lambda}) + \sum_I\Big(\sum_{t=1}^{T}\log b_{i_t}(o_t)\Big)P(O,I|\overline{\lambda})
\]</span> 分别对它们使用拉格朗日乘子法极大化得到（以后再补充细节）： - 初始状态概率: <span class="math inline">\(\pi_i=\frac{P(O,q_1=i|\overline{\lambda})}{P(O|\overline{\lambda})}=\frac{P(O,q_1=i|\overline{\lambda})}{\sum_{i=1}^N P(O,q_1=i|\overline{\lambda})}=\gamma_1(i)\)</span></p>
<ul>
<li>观测概率： <span class="math display">\[
a_{ij}=\frac{\sum_{t=1}^{T-1}P(O,q_t=i,q_{t+1}=j|\overline(\lambda))}{\sum_{t=1}^{T-1}P(O,q_t=i|\overline{\lambda})}=\frac{\sum_{t=1}^{T-1}\xi_t(i,j)}{\sum_{t=1}^{T-1}\gamma_t(i)}
\]</span></li>
<li>转移概率： <span class="math display">\[ b_{ik}=\frac{\sum_{t=1}^TP(O,q_t=i|\overline{\lambda})I(o_t=v_k)}{\sum_{t=1}^TP(O,q_t=i|\overline{\lambda})}=\frac{\sum_{t=1,o_t=v_k}^T\gamma_t(i)}{\sum_{t=1}^T\gamma_t(i)}
\]</span> 到此，HMM的学习问题就解决了。接下来是最后一个问题，关于HMM的预测问题。</li>
</ul>
<h2 id="hmm的预测问题">HMM的预测问题</h2>
<h3 id="近似算法">近似算法</h3>
<p>略过</p>
<h3 id="维特比算法">维特比算法</h3>
<p>维特比算法实际是用动态规划解HMM的预测问题，即用DP求概率最大路径。这时一条路径对应着一个状态序列。</p>
<p>根据DP原理，最优路径具有这样的性质：如果最优路径在时刻 <span class="math inline">\(t\)</span> 通过结点 <span class="math inline">\(i_t^*\)</span>，那么这一路径从结点 <span class="math inline">\(i_t^*\)</span> 到终点 <span class="math inline">\(i_T^*\)</span> 的部分路径，对于从 <span class="math inline">\(i_t^*\)</span> 到 <span class="math inline">\(i_T^*\)</span> 的所有可能的部分路径来说，必须是最优的。因为假如不是这样，那么从 <span class="math inline">\(i_t^*\)</span> 到 <span class="math inline">\(i_T^*\)</span> 就有另一条更好的部分路径存在，如果把它和从 <span class="math inline">\(i_1^*\)</span> 到达 <span class="math inline">\(i_t*\)</span> 的部分路径连接起来，就会形成一条比原来的路径更优的路径，这是矛盾的。依据这一原理，我们只需从时刻 <span class="math inline">\(t=1\)</span> 开始递推地计算在时刻 <span class="math inline">\(t\)</span> 状态为 <span class="math inline">\(i\)</span>的各条部分路径的最大概率，直至得到时刻 <span class="math inline">\(t=T\)</span> 状态为 <span class="math inline">\(i\)</span> 的各条路径的最大概率。时刻 <span class="math inline">\(t=T\)</span> 的最大概率即为最优路径的概率 <span class="math inline">\(P^*\)</span>，最优路径的终结点 <span class="math inline">\(i_{T=1}^*\)</span> 也同时得到。之后，为了找出最优路径的各个结点，从终结点 <span class="math inline">\(i_T^*\)</span> 开始，由后向前逐步求得结点 <span class="math inline">\(i_{T-1}^*,\dots,i_1^*\)</span>，得到最优路径 <span class="math inline">\(I^*=(i_1^*,i_2^*,\dots,i_T^*)\)</span>。这就是维特比算法。</p>
<p>定义一个变量 <span class="math inline">\(\delta_t(i)\)</span>：在时刻 <span class="math inline">\(t\)</span> 状态为 <span class="math inline">\(i\)</span> 的所有路径中，概率的最值。具体的算法过程为： - 定义： <span class="math display">\[
\delta_t(i)= \underset{i_1,i_2,\dots,i_{t-1}}{\max}P(q_t=i,i_{t-1},\dots,i_1,o_t,\dots,o_1|\lambda)
\]</span> - 递推： <span class="math display">\[
\delta_1(i)=\pi_ib_i(o_1)\\
\delta_{t+1}(i)=\underset{i_1,i_2,\dots,i_{t}}{\max}P(q_t=i,i_{t},\dots,i_1,o_t,\dots,o_1|\lambda)\\=\underset{1\leq j \leq N}{\max}\Big(\delta_t(j)a_{ji}b_i(o_{t+1})\Big)
\]</span></p>
<ul>
<li>终止： <span class="math display">\[
P^*=\underset{1\leq i \leq N}{\max}\delta_T(i)
\]</span></li>
</ul>
<h1 id="参考文献">参考文献</h1>
<p>李航 《统计学习方法》,2012.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/04/TensorFlow基础知识/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Spencer">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/head.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Learn Machine Learning">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/04/TensorFlow基础知识/" itemprop="url">TensorFlow基础知识</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-04T17:40:06+08:00">
                2018-01-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>一些激活函数不是<code>zero centered</code>，例如<code>sigmoid</code>，对于大多数计算图上的算法， 这就需要我们先对数据进行<code>zero-mean</code></p>
<p><code>softsign</code>函数也被用作激活函数。这个函数的形式为 <span class="math inline">\(\frac{x}{|x| + 1}\)</span>，它被认为是<code>sign</code>函数的连续近似。可以使用下面的代码实现： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(sess.run(tf.nn.softsign([<span class="number">-1.</span>, <span class="number">0.</span>, <span class="number">-1.</span>])))</span><br></pre></td></tr></table></figure></p>
<p>另外一个函数，<code>softplus</code>是一个<code>ReLU</code>函数的平滑版。这个函数的形式为： <span class="math inline">\(\log(\exp(x) + 1)\)</span>，用代码的形式为： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(sess.run(tf.nn.softplus([<span class="number">-1.</span>, <span class="number">0.</span>, <span class="number">-1.</span>])))</span><br></pre></td></tr></table></figure></p>
<p>当输入增加时<code>softplus</code>趋向于无穷大，而<code>softsign</code>趋向于1； 当输入减小时<code>softplus</code>趋向于0，而<code>softsign</code>趋向于-1。</p>
<p><code>Exponential Linear Unit(ELU)</code>和<code>softplus</code>很相似，区别就是它的下界是-1而不是0。函数公式为： <span class="math display">\[
  ELU(x) =
  \left\{
   \begin{aligned}
      \exp(x) + 1  \ \ \ \ \  x &lt; 0  \\
      x  \ \ \ \ \ x &gt; = 0   \\
   \end{aligned}
   \right.
\]</span> 用TensorFlow实现如下： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(sess.run(tf.nn.elu([<span class="number">-1.</span>, <span class="number">0.</span>, <span class="number">-1.</span>])))</span><br></pre></td></tr></table></figure></p>
<p>这些激活函数是我们把非线性引入神经网络或者未来的其他计算图。需要注意的是，我们在网络的哪里使用激活函数。如果激活函数的输出范围在0和1之间（sigmoid），那么计算图只能输出0到1之间的值。 如果激活函数是在内部和隐藏结点中，那么我们希望意识到这个输出范围会作用于我们的张量上。如果张量被归一到0均值，我们就是希望使用一个激活函数尽可能保持在0附近变化。这个意味着我们希望选择一个激活函数，例如tanh或者sigmoid。如果张量全部被处理为正值的，那么我们理想地要选择一个激活函数保持变化在正值域附近。</p>
<h2 id="使用tensorflow和python处理数据">使用TensorFlow和Python处理数据</h2>
<h2 id="layering-nested-operations">Layering Nested Operations</h2>
<p>接下来将学习如何将多个操作放入同一个计算图。怎样把一些操作连接在一起是很重要的。这需要在计算图中设置<code>layered operations</code>，下面看一个例子：使用2个矩阵乘以一个<code>placeholder</code>，然后把它们相加起来。这2个矩阵使用一个3维的<code>numpy</code>数组。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">my_array = np.array([[<span class="number">1.</span>, <span class="number">3.</span>, <span class="number">5.</span>, <span class="number">7.</span>, <span class="number">9.</span>],</span><br><span class="line">                     [<span class="number">-2.</span>, <span class="number">0.</span>, <span class="number">2.</span>, <span class="number">4.</span>, <span class="number">6.</span>],</span><br><span class="line">                     [<span class="number">-6.</span>, <span class="number">-3.</span>, <span class="number">0.</span>, <span class="number">3.</span>, <span class="number">6.</span>]])</span><br><span class="line">x_vals = np.array([my_array,my_array + <span class="number">1</span>])</span><br><span class="line">x_data = tf.placeholder(tf.float32, shape=(<span class="number">3</span>, <span class="number">5</span>))</span><br></pre></td></tr></table></figure></p>
<p>接下来，我们创建我们将使用的常量，用于矩阵乘法和加法： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">m1 = tf.constant([[<span class="number">1.</span>],[<span class="number">0.</span>],[<span class="number">-1.</span>],[<span class="number">2.</span>],[<span class="number">4.</span>]])</span><br><span class="line">m2 = tf.contant([[<span class="number">2.</span>]])</span><br><span class="line">a1 = tf.constant([[<span class="number">10.</span>]])</span><br></pre></td></tr></table></figure></p>
<p>然后声明操作，并且把它们加入到图： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">prod1 = tf.matmul(x_data, m1)</span><br><span class="line">prod2 = tf.matmul(prod1, m2)</span><br><span class="line">add1 = tf.add(prod2, a1)</span><br></pre></td></tr></table></figure></p>
<p>最后，将数据传入到图中： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  <span class="keyword">for</span> x_val <span class="keyword">in</span> x_vals:</span><br><span class="line">    print(sess.run(add1,feed_dict=&#123;x_data: x_val&#125;))</span><br></pre></td></tr></table></figure></p>
<h2 id="使用多层">使用多层</h2>
<p>首先我们使用<code>numpy</code>创建一个2D图像。这个图像是一个<code>4 x 4</code>像素的图像。我们将在4个维度中创建，第一个和最后一个维度的大小都为1。需要注意的是一些TensorFlow图像函数都是操作一个四维图像。那些四个维度是指：图像变换，高度，宽度以及通道，为了得到一个通道的一个图像，我们设置了其中的2个维度为1： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x_shape = [<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">1</span>]</span><br><span class="line">x_val = np.random.uniform(size=x_shape)</span><br></pre></td></tr></table></figure></p>
<p>接下来，创建一个<code>placeholder</code>： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x_data = tf.placeholder(tf.float32, shape=x_shape)</span><br></pre></td></tr></table></figure></p>
<p>为了根据我们的 <span class="math inline">\(4 x 4\)</span>的图像创建一个移动窗口平均，我们将使用内建的函数，它将沿着$ 2 x 2$形状的一个窗口以及一个常数进行卷积。这个函数是TensorFlow中用于图像处理非常常用的一个函数，名字为<code>conv2d()</code>，它需要一个窗口的分段点积以及一个滤波器。同时，我们也必须为移动窗口在两个方向上指定一个<code>stride</code>。这里，我们将计算四个移动窗口平均，左上角，右上角，左下角以及右下角四个像素。通过创建一个<span class="math inline">\(2 x 2\)</span>的窗口以及在每个方向设置长度为2的<code>stride</code>。为了取平均，我们使用常数<span class="math inline">\(0.25\)</span>来卷积这个<span class="math inline">\(2 x 2\)</span>的窗口： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">my_filter = tf.constant(<span class="number">0.25</span>, shape=[<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">my_strides = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>]</span><br><span class="line">mov_avg_layer = tf.nn.conv2d(x_data,my_filter,my_strides,</span><br><span class="line">                             padding=<span class="string">'SAME'</span>,name=<span class="string">'Moving_Avg_Window'</span>)</span><br></pre></td></tr></table></figure></p>
<p>现在我们定义一个自定义层，它将在<span class="math inline">\(2 x 2\)</span>输出的移动窗口平均上进行操作。自定义的函数首先使用另外一个 <span class="math inline">\(2 x 2\)</span>的矩阵张量与输入相乘，然后增加1。之后，我们对每个元素执行<code>sigmoid</code>并且返回<span class="math inline">\(2 x 2\)</span>矩阵。因为矩阵乘法只能操作二维的矩阵，我们需要扔掉额外的大小为1的图像的维度。<code>TensorFlow</code>可以使用内建函数<code>squeeze()</code>来处理这种情况。这里是我们定义的新的层： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">custom_layer</span><span class="params">(input_matrix)</span>:</span></span><br><span class="line">  input_matrix_sqeezed = tf.squeeze(input_matrix)</span><br><span class="line">  A = tf.constant([[<span class="number">1.</span>, <span class="number">2.</span>],[<span class="number">-1.</span>, <span class="number">3.</span>]])</span><br><span class="line">  b = tf.constant(<span class="number">1.</span>, shape=[<span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line">  temp1 = tf.matmul(A, input_matrix_sqeezed)</span><br><span class="line">  temp = tf.add(temp1, b) <span class="comment"># Ax + b</span></span><br><span class="line">  <span class="keyword">return</span> tf.sigmoid(temp)</span><br></pre></td></tr></table></figure></p>
<p>现在，我们需要把新的层放置到图中。我们将使用一个有名的范围（a named scope），使得它在计算图中是唯一的以及可展开和压缩的，如下： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  <span class="keyword">with</span> tf.name_scope(<span class="string">'Custom_Layer'</span>) <span class="keyword">as</span> scope:</span><br><span class="line">    custom_layer1 = custom_layer(mov_avg_layer)</span><br><span class="line">    print(sess.run(custom_layer1,feed_dict=&#123;x_data: x_val&#125;))</span><br></pre></td></tr></table></figure></p>
<h1 id="实现损失函数">实现损失函数</h1>
<p>损失函数对于机器学习算法很重要。它们度量了模型的输出与目标（真实）值之间的距离。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">x_vals = tf.linspace(<span class="number">-1.</span>, <span class="number">1.</span>, <span class="number">500</span>)</span><br><span class="line">target = tf.constant(<span class="number">0.</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="l_2-norm-损失函数"><span class="math inline">\(L_2\)</span> norm 损失函数</h2>
<p><span class="math inline">\(L_2\)</span> norm 损失函数也被称为欧几里得损失函数。它就是和目标值的距离的平方。这里我们将假设目标值为<span class="math inline">\(0\)</span>，从而计算损失函数。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">l2_y_vals = tf.square(target - x_vals)</span><br><span class="line">l2_y_out = sess.run(l2_y_vals)</span><br></pre></td></tr></table></figure></p>
<h2 id="l_1-norm-损失函数"><span class="math inline">\(L_1\)</span> norm 损失函数</h2>
<p><span class="math inline">\(L_1\)</span> norm 损失也被称为绝对值损失函数。不是取差的平方，而是取绝对值。<span class="math inline">\(L_1\)</span> norm 对于异常值比<span class="math inline">\(L_2\)</span> norm更好，因为对于很大的值，它不是陡峭的。但是，<span class="math inline">\(L_1\)</span>在目标值上不是平滑的，这会导致算法不能很好地收敛。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">l1_y_vals = tf.abs(target - x_vals)</span><br><span class="line">l1_y_out = sess.run(l1_y_vals)</span><br></pre></td></tr></table></figure></p>
<h2 id="pseudo-huber-损失函数">Pseudo-Huber 损失函数</h2>
<p>它是Huber损失的连续并且平滑的一个近似。这个损失函数在目标值附近是凸面的，并且对于异常值是不陡峭的，这样就获得了<span class="math inline">\(L_1\)</span> 和 <span class="math inline">\(L_2\)</span> norms的优点。它的形式取决于一个额外的参数，<span class="math inline">\(delta\)</span>,决定了它有多陡峭。我们将画出2幅图，分别是<span class="math inline">\(delta = 0.25\)</span>和<span class="math inline">\(delta2 = 5\)</span>来展示它们的不同： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">delta1 = tf.constant(<span class="number">0.25</span>)</span><br><span class="line">phuber1_y_vals = tf.mul(tf.square(delta1), tf.sqrt(<span class="number">1.</span> +    tf.square((target - x_vals) / delta1)) - <span class="number">1.</span>)</span><br><span class="line">phuber1_y_out = sess.run(phuber1_y_vals)</span><br><span class="line"></span><br><span class="line">delta2 = tf.constant(<span class="number">5</span>)</span><br><span class="line">phuber2_y_vals = tf.mul(tf.square(delta2), tf.sqrt(<span class="number">1.</span> + tf.square((target - x_vals) / delta2)) - <span class="number">1.</span>)</span><br><span class="line">phuber2_y_out = sess.run(phuber2_y_vals)</span><br></pre></td></tr></table></figure></p>
<h2 id="分类损失函数主要用于评估预测类别型结果的损失">分类损失函数主要用于评估预测类别型结果的损失</h2>
<p>我们将需要重新定义预测结果(x_vals)以及目标变量。我们将保存输出并且在下一节中绘制它们。使用下面的代码： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x_vals = tf.linspace(<span class="number">-3.</span>, <span class="number">5.</span>, <span class="number">500</span>)</span><br><span class="line">target = tf.constant(<span class="number">1.</span>)</span><br><span class="line">targets = tf.fill([<span class="number">500</span>, ], <span class="number">1.</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="hinge-损失函数">Hinge 损失函数</h2>
<p>它是在支持向量机中使用最多的损失函数，但是也能够被用在神经网络中。它意味着计算2个目标类别之间的损失，1和-1.在下面的代码中，我们正在使用目标值1，因此我们的预测结果离1越近，损失值就越小： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hinge_y_vals = tf.maximum(<span class="number">0.</span>, <span class="number">1.</span> - tf.mul(target, x_vals))</span><br><span class="line">hinge_y_out = sess.run(hinge_y_vals)</span><br></pre></td></tr></table></figure></p>
<h2 id="交叉熵损失函数">交叉熵损失函数</h2>
<p>它是针对二分类的，有时候也被称为<code>logistic</code>损失函数。它出现在当我们在预测2个类别为0或者1的时候。我们期望度量实际的类别（0或者1）与预测的值之间的距离，预测的值通常可能会是0到1之间的一个实数。为了度量这个距离，我们能够使用信息论中的交叉熵公式，如下： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">xentropy_y_vals = - tf.mul(target,tf.log(x_vals)) - tf.mul((<span class="number">1.</span> - target), tf.log(<span class="number">1.</span> - x_vals))</span><br><span class="line">xentropy_y_out = sess.run(xentropy_y_vals)</span><br></pre></td></tr></table></figure></p>
<h2 id="sigmoid-cross-entropy-loss">sigmoid cross entropy loss</h2>
<p>它和上面的损失很像，区别是在我们将<code>x_values</code>放入交叉熵损失函数之前，把<code>x_values</code>变成了<code>sigmoid</code>函数。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">xentropy_sigmoid_y_vals = tf.nn.sigmoid_cross_entropy_with_logits(x_vals, targets)</span><br><span class="line">xentropy_sigmoid_y_out = sess.run(xentropy_sigmoid_y_vals)</span><br></pre></td></tr></table></figure></p>
<h2 id="weighted-cross-entropy-loss">Weighted cross entropy loss</h2>
<p>它是sigmoid_cross_entropy_with_logits 损失函数的加权版本。我们为正例提供一个权重。例如，我们对正例给予一个<span class="math inline">\(0.5\)</span>的权重，如下： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">weight = tf.constant(<span class="number">0.5</span>)</span><br><span class="line">xentropy_weighted_y_vals = tf.nn.weighted_cross_entropy_with_logits(x_vals, targets, weight)</span><br><span class="line">xentropy_weighted_y_out = sess.run(xentropy_weighted_y_vals)</span><br></pre></td></tr></table></figure></p>
<h2 id="softmax-cross-engropy-损失">softmax cross-engropy 损失</h2>
<p>它可以处理非标准化（non-normalization）的输出。这个函数是被用来度量当仅含一个目标类别而不是多个的损失函数。由于这个原因，函数会把输出转换为一个概率分布，这是通过<code>softmax</code>实现的，然后依赖一个真实的概率分布来计算损失函数，如下： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">unscaled_logits = tf.constant([[<span class="number">1.</span>, <span class="number">-3.</span>, <span class="number">10.</span>]])</span><br><span class="line">target_dist = tf.constant([[<span class="number">0.1</span>, <span class="number">0.02</span>, <span class="number">0.88</span>]])</span><br><span class="line">softmax_xentropy = tf.nn.softmax_cross_entropy_with_logits(unscaled_logits,target_dist)</span><br><span class="line">print(sess.run(softmax_xentropy))</span><br></pre></td></tr></table></figure></p>
<h2 id="sparse-softmax-cross-engropy-损失">sparse softmax cross-engropy 损失</h2>
<p>它和上面的情况类似，但不是让目标值成为一个概率分布，它是哪个类别为真的一个索引。</p>
<h1 id="实现反向传播">实现反向传播</h1>
<p>创建数据，placeholder以及A变量 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x_vals = np.random.normal(<span class="number">1</span>, <span class="number">0.1</span>, <span class="number">100</span>)</span><br><span class="line">y_vals = np.repeat(<span class="number">10.</span>, <span class="number">100</span>)</span><br><span class="line">x_data = tf.placeholder(shape=[<span class="number">1</span>], dtype=tf.float32)</span><br><span class="line">y_target = tf.placeholder(shape=[<span class="number">1</span>],dtype=tf.float32)</span><br><span class="line">A = tf.Variable(tf.random_normal(shape=[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure></p>
<p>我们把乘法操作加到图中： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">my_output = tf.mul(x_data, A)</span><br></pre></td></tr></table></figure></p>
<p>接下来我们增加<span class="math inline">\(L_2\)</span>损失函数： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss = tf.square(my_output - y_target)</span><br></pre></td></tr></table></figure></p>
<p>上面都是构造图，在运行图之前需要初始化所有的variable： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">init = tf.initialize_all_variables()</span><br></pre></td></tr></table></figure></p>
<p>接下来我们必须声明一个方式在图中优化我们的变量。我们声明一个优化算法。大多数优化算法需要知道在每一步迭代中要“前进多远”。这个距离是由学习率控制的。如果我们的学习率太大了，那么我们的算法可能会越过最小值，但是如果我们的学习率太小了，那么我们的算法可能会花很长时间才能收敛；这个关系到梯度消失/爆炸问题。学习率对于收敛有一个很大的影响。这里我们暂时使用标准的梯度下降算法，存在许多不同的优化算法，它们操作不一样并且取决于不同问题能够做得更好或者更糟糕。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">my_opt = tf.train.GradientDescentOptimizer(learning_rate=<span class="number">0.02</span>)</span><br><span class="line">train_step = my_opt.minimize(loss)</span><br></pre></td></tr></table></figure></p>
<p>最后的步骤就是告诉TensorFlow训练多次。我们将训练101次并且每第25次迭代就输出我们的结果。为了训练，我们将选择一个随机数<span class="math inline">\(x\)</span>和<span class="math inline">\(y\)</span>，并把它们放入图中。TensorFlow将自动地计算损失，并且逐步改变偏置<span class="math inline">\(A\)</span>来最小化损失： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    rand_index = np.random.choice(<span class="number">100</span>)</span><br><span class="line">    rand_x = [x_vals[rand_index]]</span><br><span class="line">    rand_y = [y_vals[rand_index]]</span><br><span class="line">    sess.run(train_step, feed_dict = &#123;x_data: rand_x,y_target:rand_y&#125;)</span><br><span class="line">    <span class="keyword">if</span> (i + <span class="number">1</span>) % <span class="number">25</span> == <span class="number">0</span>:</span><br><span class="line">      print(<span class="string">'Step #'</span> + str(i+<span class="number">1</span>) + <span class="string">' A= '</span> + str(sess.run(A)))</span><br><span class="line">      print(<span class="string">'Loss = '</span>+ str(sess.run(loss,feed_dict=&#123;x_data:rand_x,y_target:rand_y&#125;)))</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/12/10/新篇章/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Spencer">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/head.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Learn Machine Learning">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/12/10/新篇章/" itemprop="url">新篇章</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-12-10T14:40:41+08:00">
                2017-12-10
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>过去维护了3年的博客数据丢失，未能找回，以后将做好备份。本博客主要用于记录平常遇到的一些 关于机器学习算法的问题，依旧专注于：<strong>传统机器学习</strong>、<strong>深度学习</strong>、<strong>推荐系统</strong>，<strong>自 然语言处理</strong> 等方向。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/head.jpg"
                alt="Spencer" />
            
              <p class="site-author-name" itemprop="name">Spencer</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            

          </nav>

          

          <div class="links-of-author motion-element">
            
          </div>

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Spencer</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.3</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
